{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b059328c7cb948838f6f81caf6753f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/453 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a652a4f480e4d2e8be68557c4347dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/228k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be659619cd844ea9edccbcb7f5093e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/717k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1024af448e44818f8becec8d6c8040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd93ac4ab7642939be7e3440cd7c407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/754 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4299bc9056c74365b8613d000cf0ceff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6212578eec4621908475479a269a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from semantic_search import store\n",
    "reload(store)\n",
    "from semantic_search.store import LocalEmbeddingModel\n",
    "\n",
    "model = LocalEmbeddingModel(\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2',  # 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=64,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking and encoding: 100%|██████████| 4/4 [00:00<00:00, 585.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 8 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tmp_input = \"Using pooling, it generates from a variable sized sentence a fixed sized sentence embedding. This layer also allows to use the CLS token if it is returned by the underlying word embedding model. You can concatenate multiple poolings together.\"\n",
    "\n",
    "inputs = [tmp_input*10, tmp_input*3, tmp_input, tmp_input*30]\n",
    "\n",
    "_, all_chunks_encoded = model.chunk_and_encode(inputs, progress_bar=True)\n",
    "\n",
    "# Flatten encoded\n",
    "tmp = {}\n",
    "for single_text_encoded in all_chunks_encoded:\n",
    "    for k, v in single_text_encoded.items():\n",
    "        if k not in tmp:\n",
    "            tmp[k] = []\n",
    "        tmp[k].append(v)\n",
    "encoded_flattened = {k: torch.cat(v) for k, v in tmp.items()}\n",
    "\n",
    "# Get embeddings for all chunks\n",
    "print(f\"Generating embeddings for {len(list(encoded_flattened.values())[0])} chunks...\")\n",
    "embeddings = model.get_embeddings(encoded_flattened, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "_, encoded = model.chunk_and_encode(tmp_input*100)\n",
    "emb = model.get_embeddings(encoded)\n",
    "\n",
    "\n",
    "encoded_input = model.tokenizer(tmp_input*100, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model.model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[0] == sentence_embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev for new cleaner store setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from semantic_search import store\n",
    "reload(store)\n",
    "from semantic_search.store import LocalEmbeddingModel, FAISSDocumentStore\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 22:20:02.927660: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-12 22:20:04.794705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded index with 41220 vectors\n"
     ]
    }
   ],
   "source": [
    "ds = FAISSDocumentStore(db_dir='/cluster/home/lcarretero/workspace/dsl/dsl-research-assistant/db/hybrid-dev')\n",
    "assert ds.load_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chunk_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W2194775991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2194775991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W1686810756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W4385245566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W4385245566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41215</th>\n",
       "      <td>W4317940424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41216</th>\n",
       "      <td>W4386977288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41217</th>\n",
       "      <td>W4387995378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41218</th>\n",
       "      <td>W4394656229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41219</th>\n",
       "      <td>W4292423008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41220 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               doc_id\n",
       "chunk_id             \n",
       "0         W2194775991\n",
       "1         W2194775991\n",
       "2         W1686810756\n",
       "3         W4385245566\n",
       "4         W4385245566\n",
       "...               ...\n",
       "41215     W4317940424\n",
       "41216     W4386977288\n",
       "41217     W4387995378\n",
       "41218     W4394656229\n",
       "41219     W4292423008\n",
       "\n",
       "[41220 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.chunk_store[list(set(['doc_id']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Chunk ID W3197456663 not found in chunk_store.\n",
      "Warning: Chunk ID W3003791552 not found in chunk_store.\n",
      "Warning: Chunk ID W4221145940 not found in chunk_store.\n",
      "Warning: Chunk ID W4387490658 not found in chunk_store.\n",
      "Warning: Chunk ID W2994818707 not found in chunk_store.\n",
      "Warning: Chunk ID W4385573874 not found in chunk_store.\n",
      "Warning: Chunk ID W3133542152 not found in chunk_store.\n",
      "Warning: Chunk ID W4237823019 not found in chunk_store.\n",
      "Warning: Chunk ID W4214518393 not found in chunk_store.\n",
      "Warning: Chunk ID W1530404542 not found in chunk_store.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.search('What is the main idea of the paper?', top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev for new hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/lcarretero/python_envs/dsl-research-assistant/lib/python3.11/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'store_raw_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msemantic_search\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISSDocumentStore\n\u001b[32m      3\u001b[39m ds = FAISSDocumentStore(db_dir=\u001b[33m'\u001b[39m\u001b[33m/cluster/home/lcarretero/workspace/dsl/dsl-research-assistant/db/sentence-transformers_all-MiniLM-L6-v2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dsl/dsl-research-assistant/src/semantic_search/store/store.py:206\u001b[39m, in \u001b[36mFAISSDocumentStore.load_store\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28mself\u001b[39m.index_metric = metadata[\u001b[33m'\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mindex_metric\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    205\u001b[39m \u001b[38;5;28mself\u001b[39m.store_raw_embeddings = metadata[\u001b[33m'\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mstore_raw_embeddings\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28mself\u001b[39m.store_raw_documents = \u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstore_raw_documents\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28mself\u001b[39m.chunk_store_columns = metadata[\u001b[33m'\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mchunk_store_columns\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    208\u001b[39m \u001b[38;5;28mself\u001b[39m.use_bm25 = metadata[\u001b[33m'\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33muse_bm25\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'store_raw_documents'"
     ]
    }
   ],
   "source": [
    "from semantic_search.store.store import FAISSDocumentStore\n",
    "\n",
    "ds = FAISSDocumentStore(db_dir='/cluster/home/lcarretero/workspace/dsl/dsl-research-assistant/db/sentence-transformers_all-MiniLM-L6-v2')\n",
    "assert ds.load_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rank': 1,\n",
       "  'score': 0.55700177,\n",
       "  'doc_id': 'W3173515979',\n",
       "  'doi': '10.1109/cvprw53098.2021.00286',\n",
       "  'topic': 'Advanced Image Processing Techniques'},\n",
       " {'rank': 2,\n",
       "  'score': 0.5426627,\n",
       "  'doc_id': 'W3024079478',\n",
       "  'doi': '10.1109/wacv45572.2020.9093474',\n",
       "  'topic': 'Face recognition and analysis'},\n",
       " {'rank': 3,\n",
       "  'score': 0.53668606,\n",
       "  'doc_id': 'W3178812510',\n",
       "  'doi': '10.1109/icicsp55539.2022.10050624',\n",
       "  'topic': 'Advanced Neural Network Applications'},\n",
       " {'rank': 4,\n",
       "  'score': 0.4742528,\n",
       "  'doc_id': 'W4386066489',\n",
       "  'doi': '10.1109/cvpr52729.2023.01670',\n",
       "  'topic': 'Robotics and Sensor-Based Localization'},\n",
       " {'rank': 5,\n",
       "  'score': 0.46302596,\n",
       "  'doc_id': 'W3085567564',\n",
       "  'doi': '10.1109/jsen.2020.3023486',\n",
       "  'topic': 'Non-Invasive Vital Sign Monitoring'},\n",
       " {'rank': 6,\n",
       "  'score': 0.46051693,\n",
       "  'doc_id': 'W2766042539',\n",
       "  'doi': '10.1145/3123266.3123451',\n",
       "  'topic': 'Anomaly Detection Techniques and Applications'},\n",
       " {'rank': 7,\n",
       "  'score': 0.45910347,\n",
       "  'doc_id': 'W2740982616',\n",
       "  'doi': '10.1109/cvpr.2017.186',\n",
       "  'topic': 'Image Enhancement Techniques'},\n",
       " {'rank': 8,\n",
       "  'score': 0.45882607,\n",
       "  'doc_id': 'W284229479',\n",
       "  'doi': '10.1093/oso/9780195148558.001.0001',\n",
       "  'topic': 'Environmental, Ecological, and Cultural Studies'},\n",
       " {'rank': 9,\n",
       "  'score': 0.4585931,\n",
       "  'doc_id': 'W2573048268',\n",
       "  'doi': '10.1112/blms/28.5.544',\n",
       "  'topic': 'Digital Image Processing Techniques'},\n",
       " {'rank': 10,\n",
       "  'score': 0.4530817,\n",
       "  'doc_id': 'W3183673520',\n",
       "  'doi': '10.1109/cvpr46437.2021.00551',\n",
       "  'topic': 'Visual Attention and Saliency Detection'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.search('What is the main idea of the paper?', top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doi</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chunk_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W2194775991</td>\n",
       "      <td>10.1109/cvpr.2016.90</td>\n",
       "      <td>Advanced Neural Network Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2194775991</td>\n",
       "      <td>10.1109/cvpr.2016.90</td>\n",
       "      <td>Advanced Neural Network Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W1686810756</td>\n",
       "      <td>nan</td>\n",
       "      <td>Advanced Vision and Imaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W4385245566</td>\n",
       "      <td>10.48550/arxiv.1706.03762</td>\n",
       "      <td>Natural Language Processing Techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W4385245566</td>\n",
       "      <td>10.48550/arxiv.1706.03762</td>\n",
       "      <td>Natural Language Processing Techniques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               doc_id                        doi  \\\n",
       "chunk_id                                           \n",
       "0         W2194775991       10.1109/cvpr.2016.90   \n",
       "1         W2194775991       10.1109/cvpr.2016.90   \n",
       "2         W1686810756                        nan   \n",
       "3         W4385245566  10.48550/arxiv.1706.03762   \n",
       "4         W4385245566  10.48550/arxiv.1706.03762   \n",
       "\n",
       "                                           topic  \n",
       "chunk_id                                          \n",
       "0           Advanced Neural Network Applications  \n",
       "1           Advanced Neural Network Applications  \n",
       "2                    Advanced Vision and Imaging  \n",
       "3         Natural Language Processing Techniques  \n",
       "4         Natural Language Processing Techniques  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.chunk_store.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dsl-research-assistant)",
   "language": "python",
   "name": "dsl-research-assistant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
